{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOw/ZsHGosS8FQHDJYp8M0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/State-of-the-Art/blob/main/Few_Shot_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic84elOUNaAa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Define the Prototypical Network\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Sampling task with valid rotation indices\n",
        "def sample_task(dataset, n_way, n_shot, n_query):\n",
        "    rotation_indices = [0, 1, 2, 3]  # Define rotation classes (aligned with model output_dim)\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "    for c in rotation_indices[:n_way]:  # Limit classes to valid rotation indices\n",
        "        indices = torch.nonzero(torch.tensor(dataset.targets) == c).squeeze()\n",
        "        indices = indices[torch.randperm(len(indices))[:n_shot + n_query]]\n",
        "        support_set.append(indices[:n_shot])\n",
        "        query_set.append(indices[n_shot:])\n",
        "    return support_set, query_set, rotation_indices[:n_way]\n",
        "\n",
        "# Compute prototypes and loss\n",
        "def compute_prototypes_and_loss(model, dataset, support_set, query_set, classes, output_dim):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Compute prototypes from support set\n",
        "    prototypes = []\n",
        "    for indices in support_set:\n",
        "        support_data = dataset.data[indices].view(-1, 28 * 28).float().to(device) / 255.0\n",
        "        support_embeddings = model(support_data)\n",
        "        prototypes.append(support_embeddings.mean(dim=0))\n",
        "    prototypes = torch.stack(prototypes)\n",
        "\n",
        "    # Compute query embeddings\n",
        "    all_query_embeddings = []\n",
        "    all_query_labels = []\n",
        "    for indices, class_idx in zip(query_set, classes):\n",
        "        query_data = dataset.data[indices].view(-1, 28 * 28).float().to(device) / 255.0\n",
        "        query_embeddings = model(query_data)\n",
        "        all_query_embeddings.append(query_embeddings)\n",
        "        all_query_labels.append(torch.full((len(indices),), class_idx, dtype=torch.long).to(device))\n",
        "    query_embeddings = torch.cat(all_query_embeddings)\n",
        "    query_labels = torch.cat(all_query_labels)\n",
        "\n",
        "    # Compute distances and classify\n",
        "    distances = torch.cdist(query_embeddings, prototypes)\n",
        "    predicted_labels = torch.argmin(distances, dim=1)\n",
        "\n",
        "    # Compute loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(-distances, query_labels)  # Negative distances for logits\n",
        "    return loss, predicted_labels, query_labels\n",
        "\n",
        "# Example usage\n",
        "dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "support_set, query_set, classes = sample_task(dataset, n_way=4, n_shot=5, n_query=15)  # Align n_way with valid indices\n",
        "\n",
        "# Define model and optimizer\n",
        "model = PrototypicalNetwork(input_dim=784, hidden_dim=256, output_dim=128)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    loss, predictions, query_labels = compute_prototypes_and_loss(\n",
        "        model, dataset, support_set, query_set, classes, output_dim=128\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    accuracy = (predictions == query_labels).float().mean().item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}, Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Define the Prototypical Network\n",
        "class PrototypicalNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "# Sample a few-shot learning task\n",
        "def sample_task(dataset, n_way, n_shot, n_query):\n",
        "    rotation_indices = [0, 1, 2, 3]  # Define rotation classes (aligned with model output_dim)\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "    for c in rotation_indices[:n_way]:  # Limit classes to valid rotation indices\n",
        "        indices = torch.nonzero(dataset.targets == c).squeeze()  # Avoid redundant tensor wrapping\n",
        "        indices = indices[torch.randperm(len(indices))[:n_shot + n_query]]\n",
        "        support_set.append(indices[:n_shot])\n",
        "        query_set.append(indices[n_shot:])\n",
        "    return support_set, query_set, rotation_indices[:n_way]\n",
        "\n",
        "# Compute prototypes and classify\n",
        "def compute_prototypes_and_loss(model, dataset, support_set, query_set, classes, output_dim):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Compute prototypes from support set\n",
        "    prototypes = []\n",
        "    for indices in support_set:\n",
        "        support_data = dataset.data[indices].view(-1, 28 * 28).float().to(device) / 255.0\n",
        "        support_embeddings = model(support_data)\n",
        "        prototypes.append(support_embeddings.mean(dim=0))\n",
        "    prototypes = torch.stack(prototypes)\n",
        "\n",
        "    # Compute query embeddings\n",
        "    all_query_embeddings = []\n",
        "    all_query_labels = []\n",
        "    for indices, class_idx in zip(query_set, classes):\n",
        "        query_data = dataset.data[indices].view(-1, 28 * 28).float().to(device) / 255.0\n",
        "        query_embeddings = model(query_data)\n",
        "        all_query_embeddings.append(query_embeddings)\n",
        "        all_query_labels.append(torch.full((len(indices),), class_idx, dtype=torch.long).to(device))\n",
        "    query_embeddings = torch.cat(all_query_embeddings)\n",
        "    query_labels = torch.cat(all_query_labels)\n",
        "\n",
        "    # Compute distances and classify\n",
        "    distances = torch.cdist(query_embeddings, prototypes)\n",
        "    predicted_labels = torch.argmin(distances, dim=1)\n",
        "\n",
        "    # Compute loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(-distances, query_labels)  # Negative distances for logits\n",
        "    return loss, predicted_labels, query_labels\n",
        "\n",
        "# Example usage\n",
        "dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "support_set, query_set, classes = sample_task(dataset, n_way=4, n_shot=5, n_query=15)  # Align n_way with valid indices\n",
        "\n",
        "# Define model and optimizer\n",
        "model = PrototypicalNetwork(input_dim=784, hidden_dim=256, output_dim=128)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    loss, predictions, query_labels = compute_prototypes_and_loss(\n",
        "        model, dataset, support_set, query_set, classes, output_dim=128\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    accuracy = (predictions == query_labels).float().mean().item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}, Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "2CTZeTe0OXLw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}