{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPAuc662nKgVq5IjxNy8ty+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/State-of-the-Art/blob/main/Capsule_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCPh-SiF8Q5Q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class CapsuleLayer(nn.Module):\n",
        "    def __init__(self, num_capsules, in_channels, out_channels, kernel_size=None, stride=None, padding=None, routing=False):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "        self.num_capsules = num_capsules\n",
        "        self.routing = routing\n",
        "\n",
        "        if not routing:  # Primary capsules: use convolutional capsules\n",
        "            self.capsules = nn.ModuleList([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding) for _ in range(num_capsules)\n",
        "            ])\n",
        "        else:  # Fully connected capsules\n",
        "            self.capsules = nn.Linear(in_channels, num_capsules * out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.routing:\n",
        "            # Apply convolution to input\n",
        "            outputs = [capsule(x) for capsule in self.capsules]\n",
        "            outputs = torch.stack(outputs, dim=1)  # (batch_size, num_capsules, ...)\n",
        "            outputs = outputs.view(x.size(0), self.num_capsules, -1)  # Flatten capsule features\n",
        "            outputs = self.squash(outputs)\n",
        "        else:\n",
        "            # Fully connected capsule layer\n",
        "            batch_size = x.size(0)\n",
        "            outputs = self.capsules(x)\n",
        "            outputs = outputs.view(batch_size, self.num_capsules, -1)\n",
        "            outputs = self.squash(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def squash(self, x):\n",
        "        \"\"\"\n",
        "        Squash function to ensure outputs are in the range [0, 1]\n",
        "        \"\"\"\n",
        "        s_squared_norm = (x ** 2).sum(dim=2, keepdim=True)\n",
        "        scale = s_squared_norm / (1 + s_squared_norm) / torch.sqrt(s_squared_norm + 1e-9)\n",
        "        return scale * x\n",
        "\n",
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self, num_classes, num_capsules, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)  # Initial convolution\n",
        "\n",
        "        # Primary capsules\n",
        "        self.primary_caps = CapsuleLayer(\n",
        "            num_capsules=num_capsules,\n",
        "            in_channels=out_channels,\n",
        "            out_channels=32,\n",
        "            kernel_size=9,\n",
        "            stride=2,\n",
        "            padding=0\n",
        "        )\n",
        "\n",
        "        # Dynamically compute the flattened size of primary_caps output\n",
        "        primary_caps_output_dim = self.compute_output_dim(\n",
        "            input_dim=self.compute_output_dim(28, kernel_size, stride, padding),\n",
        "            kernel_size=9,\n",
        "            stride=2,\n",
        "            padding=0\n",
        "        )\n",
        "        primary_caps_flattened_dim = num_capsules * 32 * (primary_caps_output_dim ** 2)\n",
        "\n",
        "        # Fully connected capsule layer\n",
        "        self.fc_caps = CapsuleLayer(\n",
        "            num_capsules=num_classes,\n",
        "            in_channels=primary_caps_flattened_dim,\n",
        "            out_channels=16,\n",
        "            routing=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # Initial convolutional layer\n",
        "        x = self.primary_caps(x)  # Primary capsules\n",
        "        x = x.view(x.size(0), -1)  # Flatten for fully connected capsules\n",
        "        x = self.fc_caps(x)  # Fully connected capsule layer\n",
        "\n",
        "        # Compute vector lengths (class probabilities)\n",
        "        x = torch.sqrt((x ** 2).sum(dim=2))  # Length of vectors as probabilities\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_output_dim(input_dim, kernel_size, stride, padding):\n",
        "        \"\"\"\n",
        "        Compute the output dimension after a convolutional layer.\n",
        "        \"\"\"\n",
        "        return math.floor((input_dim - kernel_size + 2 * padding) / stride + 1)\n",
        "\n",
        "# Example usage\n",
        "model = CapsuleNet(\n",
        "    num_classes=10,\n",
        "    num_capsules=8,\n",
        "    in_channels=1,\n",
        "    out_channels=256,\n",
        "    kernel_size=9,\n",
        "    stride=1,\n",
        "    padding=0\n",
        ")\n",
        "dummy_input = torch.randn(1, 1, 28, 28)  # Batch size 1, grayscale image, 28x28\n",
        "output = model(dummy_input)\n",
        "print(output.shape)  # Expected output shape is (1, 10), probabilities for 10 classes"
      ]
    }
  ]
}