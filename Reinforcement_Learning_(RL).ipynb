{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM5LHurbOvvlNC2AptzHBYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/State-of-the-Art/blob/main/Reinforcement_Learning_(RL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJLqVIkY-TlC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GridWorld Environment\n",
        "class GridWorld:\n",
        "    def __init__(self, size, start, goal, obstacles):\n",
        "        self.size = size\n",
        "        self.start = start\n",
        "        self.goal = goal\n",
        "        self.obstacles = obstacles\n",
        "        self.state = start\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = self.start\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.state == self.goal:\n",
        "            return self.state, 0, True\n",
        "        x, y = self.state\n",
        "        if action == 0:  # up\n",
        "            next_state = (x, y - 1)\n",
        "        elif action == 1:  # right\n",
        "            next_state = (x + 1, y)\n",
        "        elif action == 2:  # down\n",
        "            next_state = (x, y + 1)\n",
        "        else:  # left\n",
        "            next_state = (x - 1, y)\n",
        "        if (\n",
        "            next_state in self.obstacles\n",
        "            or next_state[0] < 0\n",
        "            or next_state[1] < 0\n",
        "            or next_state[0] >= self.size[0]\n",
        "            or next_state[1] >= self.size[1]\n",
        "        ):\n",
        "            next_state = self.state\n",
        "        reward = -1 if next_state != self.goal else 10\n",
        "        self.state = next_state\n",
        "        return next_state, reward, next_state == self.goal\n",
        "\n",
        "# Q-learning Algorithm\n",
        "class QLearning:\n",
        "    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=1.0, epsilon_min=0.1, epsilon_decay=0.995):\n",
        "        self.env = env\n",
        "        self.q_table = np.zeros(env.size + (4,))  # (grid_size[0], grid_size[1], 4 actions)\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.randint(4)  # Explore: choose a random action\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state])  # Exploit: choose the best action\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "        td_target = reward + self.gamma * self.q_table[next_state][best_next_action]\n",
        "        td_error = td_target - self.q_table[state][action]\n",
        "        self.q_table[state][action] += self.alpha * td_error\n",
        "\n",
        "    def train(self, episodes):\n",
        "        for episode in range(episodes):\n",
        "            state = self.env.reset()\n",
        "            done = False\n",
        "            steps = 0\n",
        "            total_reward = 0\n",
        "            while not done:\n",
        "                action = self.choose_action(state)\n",
        "                next_state, reward, done = self.env.step(action)\n",
        "                self.update(state, action, reward, next_state)\n",
        "                state = next_state\n",
        "                steps += 1\n",
        "                total_reward += reward\n",
        "            # Decay epsilon\n",
        "            self.epsilon = max(self.epsilon * self.epsilon_decay, self.epsilon_min)\n",
        "            # Log progress\n",
        "            print(f\"Episode {episode+1}: Steps = {steps}, Total Reward = {total_reward}\")\n",
        "\n",
        "    def test_agent(self):\n",
        "        state = self.env.reset()\n",
        "        done = False\n",
        "        path = [state]\n",
        "        while not done:\n",
        "            action = np.argmax(self.q_table[state])\n",
        "            state, _, done = self.env.step(action)\n",
        "            path.append(state)\n",
        "        return path\n",
        "\n",
        "    def visualize_q_table(self):\n",
        "        max_q_values = np.max(self.q_table, axis=2)\n",
        "        plt.imshow(max_q_values, cmap='viridis')\n",
        "        plt.colorbar()\n",
        "        plt.title(\"State-Action Values (Max Q)\")\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "env = GridWorld(\n",
        "    size=(5, 5),\n",
        "    start=(0, 0),\n",
        "    goal=(4, 4),\n",
        "    obstacles=[(1, 1), (2, 2), (3, 3)]\n",
        ")\n",
        "agent = QLearning(env)\n",
        "agent.train(episodes=500)\n",
        "\n",
        "# Test the trained agent\n",
        "path = agent.test_agent()\n",
        "print(f\"Path to goal: {path}\")\n",
        "\n",
        "# Visualize the Q-table\n",
        "agent.visualize_q_table()"
      ]
    }
  ]
}